{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pk\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas.plotting as pdplt\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = \"datasets/ruddit_with_text.csv\"\n",
    "\n",
    "UNUSED_COLUMNS = [\"post_id\", \"comment_id\", \"url\"]\n",
    "SCORE_COLUMN = \"offensiveness_score\"\n",
    "COMMENT_COLUMN = \"txt\"\n",
    "OFFENSIVE_LABEL = \"offensive\"\n",
    "NOT_OFFENSIVE_LABEL = \"not_offensive\"\n",
    "\n",
    "STOPWORDS_LANGUAGE = \"english\"\n",
    "MAX_DF = 0.75\n",
    "\n",
    "COUNT_VECTORIZER_PATH = \"models/count_vectorizer.pickle\"\n",
    "TF_IDF_VECTORIZER_PATH = \"models/tf_idf_vectorizer.pickle\"\n",
    "\n",
    "COUNT_SVM_MODEL_PATH = \"models/count_svm_model.pickle\"\n",
    "TF_IDF_SVM_MODEL_PATH = \"models/tf_idf_svm_model.pickle\"\n",
    "COUNT_NB_MODEL_PATH = \"models/count_nb_model.pickle\"\n",
    "TF_IDF_NB_MODEL_PATH = \"models/tf_idf_nb_model.pickle\"\n",
    "\n",
    "COUNT_SVM_TITLE = \"MODEL RESULTS: COUNT - SVM\"\n",
    "TF_IDF_SVM_TITLE = \"MODEL RESULTS: TF IDF - SVM\"\n",
    "COUNT_NB_TITLE = \"MODEL RESULTS: COUNT - NB\"\n",
    "TF_IDF_NB_TITLE = \"MODEL RESULTS: TF IDF - NB\"\n",
    "\n",
    "COUNT_SVM_STATS_PATH = \"stats/count_svm_stats.png\"\n",
    "TF_IDF_SVM_STATS_PATH = \"stats/tf_idf_svm_stats.png\"\n",
    "COUNT_NB_STATS_PATH = \"stats/count_nb_stats.png\"\n",
    "TF_IDF_NB_STATS_PATH = \"stats/tf_idf_nb_stats.png\"\n",
    "\n",
    "\n",
    "FIGURE_DPI = 240\n",
    "\n",
    "SEED = 1928\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(DATASET_PATH)\n",
    "dataset.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drops unused columns\n",
    "dataset.drop(UNUSED_COLUMNS, axis=\"columns\", inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drops deleted comments\n",
    "dataset[COMMENT_COLUMN].replace(\"[deleted]\", np.nan, inplace=True)\n",
    "dataset.dropna(subset=[COMMENT_COLUMN], inplace=True)\n",
    "dataset.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "middle = np.quantile(dataset[SCORE_COLUMN], 0.5)\n",
    "print(\"middle:\", middle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(dataset[SCORE_COLUMN], bins=\"auto\")\n",
    "plt.axvline(middle, color=\"k\")\n",
    "_ = plt.title(\"Offensiveness Score Distribution\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = dataset[COMMENT_COLUMN]\n",
    "y = dataset[SCORE_COLUMN].map(\n",
    "    lambda s: OFFENSIVE_LABEL if s > 0 else NOT_OFFENSIVE_LABEL\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer = CountVectorizer(stop_words=STOPWORDS_LANGUAGE, max_df=MAX_DF)\n",
    "count_vectorizer.fit(dataset[COMMENT_COLUMN])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_vectorizer = TfidfVectorizer(stop_words=STOPWORDS_LANGUAGE, max_df=MAX_DF)\n",
    "tf_idf_vectorizer.fit(dataset[COMMENT_COLUMN])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, train_size=0.8, random_state=SEED\n",
    ")\n",
    "count_x_train = count_vectorizer.transform(x_train)\n",
    "count_x_test = count_vectorizer.transform(x_test)\n",
    "tf_idf_x_train = tf_idf_vectorizer.transform(x_train)\n",
    "tf_idf_x_test = tf_idf_vectorizer.transform(x_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyper parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, StratifiedShuffleSplit\n",
    "\n",
    "\n",
    "def tune_params(model, param_grid, x, y):\n",
    "    sss = StratifiedShuffleSplit(n_splits=5, test_size=0.2, random_state=SEED)\n",
    "    search = GridSearchCV(model, param_grid, scoring=\"accuracy\", n_jobs=-1)\n",
    "    search.fit(x, y)\n",
    "    return pd.DataFrame(search.cv_results_), search.best_params_\n",
    "\n",
    "\n",
    "def plot_tuning_results(tuning_results, title):\n",
    "    c = tuning_results[\"param_C\"].to_numpy()\n",
    "    score = tuning_results[\"mean_test_score\"].to_numpy()\n",
    "    best_score_index = np.argmax(score)\n",
    "    best_c = c[best_score_index]\n",
    "    best_score = score[best_score_index]\n",
    "    plt.title(title)\n",
    "    plt.plot(c, score)\n",
    "    plt.scatter(best_c, best_score)\n",
    "    plt.text(\n",
    "        best_c,\n",
    "        best_score,\n",
    "        f\"({best_c:0.4f}, {best_score:0.4f})\",\n",
    "        verticalalignment=\"bottom\",\n",
    "        horizontalalignment=\"left\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_param_grid = [\n",
    "    {\n",
    "        \"kernel\": [\"linear\"],\n",
    "        \"C\": np.logspace(-1, 1, 15),\n",
    "    },\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_svm_tuning_results, count_svm_params = tune_params(\n",
    "    SVC(class_weight=\"balanced\"),\n",
    "    svm_param_grid,\n",
    "    count_x_train,\n",
    "    y_train,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_svm_tuning_results, tf_idf_svm_params = tune_params(\n",
    "    SVC(class_weight=\"balanced\"),\n",
    "    svm_param_grid,\n",
    "    tf_idf_x_train,\n",
    "    y_train,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_tuning_results(count_svm_tuning_results, \"TUNING RESULTS: COUNT - SVM\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_tuning_results(tf_idf_svm_tuning_results, \"TUNING RESULTS: TF IDF - SVM\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_svm_classifier = SVC(\n",
    "    **count_svm_params,\n",
    "    class_weight=\"balanced\",\n",
    "    probability=True,\n",
    ")\n",
    "count_svm_classifier.fit(count_x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_svm_classifier = SVC(\n",
    "    **tf_idf_svm_params,\n",
    "    class_weight=\"balanced\",\n",
    "    probability=True,\n",
    ")\n",
    "tf_idf_svm_classifier.fit(tf_idf_x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_nb_classifier = MultinomialNB()\n",
    "count_nb_classifier.fit(count_x_train.toarray(), y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_nb_classifier = GaussianNB()\n",
    "tf_idf_nb_classifier.fit(tf_idf_x_train.toarray(), y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_report_and_confusion(classifier, x_test, y_test):\n",
    "    classes = classifier.classes_\n",
    "    y_pred = classifier.predict(x_test)\n",
    "    report = pd.DataFrame(\n",
    "        classification_report(y_test, y_pred, output_dict=True)\n",
    "    ).transpose()\n",
    "    confusion = pd.DataFrame(confusion_matrix(y_test, y_pred))\n",
    "    confusion.set_axis(classes, axis=\"rows\", inplace=True)\n",
    "    confusion.set_axis(classes, axis=\"columns\", inplace=True)\n",
    "    return [report, confusion]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_report_and_confusion(report, confusion, title, fig_path):\n",
    "    fig, main_axis = plt.subplots(1, 1)\n",
    "    main_axis.axis(\"tight\")\n",
    "    main_axis.axis(\"off\")\n",
    "    [report_axis, confusion_axis] = fig.subplots(2, 1)\n",
    "    report_axis.axis(\"tight\")\n",
    "    report_axis.axis(\"off\")\n",
    "    pdplt.table(report_axis, report, loc=\"center\")\n",
    "    report_axis.set_title(title)\n",
    "    confusion_axis.axis(\"tight\")\n",
    "    confusion_axis.axis(\"off\")\n",
    "    pdplt.table(confusion_axis, confusion, loc=\"center\")\n",
    "    confusion_axis.set_title(\"Matriz de Confusão\")\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(fig_path, bbox_inches=\"tight\", dpi=FIGURE_DPI)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_stats(classifier, x_test, y_test, title, fig_path):\n",
    "    [report, confusion] = generate_report_and_confusion(classifier, x_test, y_test)\n",
    "    plot_report_and_confusion(report, confusion, title, fig_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_stats(\n",
    "    count_svm_classifier, count_x_test, y_test, COUNT_SVM_TITLE, COUNT_SVM_STATS_PATH\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_stats(\n",
    "    tf_idf_svm_classifier,\n",
    "    tf_idf_x_test,\n",
    "    y_test,\n",
    "    TF_IDF_SVM_TITLE,\n",
    "    TF_IDF_SVM_STATS_PATH,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_stats(\n",
    "    count_nb_classifier, count_x_test, y_test, COUNT_NB_TITLE, COUNT_NB_STATS_PATH\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_stats(\n",
    "    tf_idf_nb_classifier,\n",
    "    tf_idf_x_test.toarray(),\n",
    "    y_test,\n",
    "    TF_IDF_NB_TITLE,\n",
    "    TF_IDF_NB_STATS_PATH,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saves model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pickle_to_file(object, path):\n",
    "    with open(path, \"wb\") as file:\n",
    "        pk.dump(object, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_to_file(count_vectorizer, COUNT_VECTORIZER_PATH)\n",
    "pickle_to_file(tf_idf_vectorizer, TF_IDF_VECTORIZER_PATH)\n",
    "\n",
    "pickle_to_file(count_svm_classifier, COUNT_SVM_MODEL_PATH)\n",
    "pickle_to_file(tf_idf_svm_classifier, TF_IDF_SVM_MODEL_PATH)\n",
    "pickle_to_file(count_nb_classifier, COUNT_NB_MODEL_PATH)\n",
    "pickle_to_file(tf_idf_nb_classifier, TF_IDF_NB_MODEL_PATH)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comment = \"\"\n",
    "vectorized = tf_idf_vectorizer.transform([comment])\n",
    "prediction = tf_idf_svm_classifier.predict_proba(vectorized)\n",
    "print(f\"offensiveness: {prediction[0][1]}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "eb527631bb171dc6780ad93b516f58282b63f6e85a0ece7e5e91665eeb4222d6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
