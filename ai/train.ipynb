{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pk\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas.plotting as pdplt\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.svm import SVC\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = \"datasets/ruddit_with_text.csv\"\n",
    "\n",
    "UNUSED_COLUMNS = [\"post_id\", \"comment_id\", \"url\"]\n",
    "SCORE_COLUMN = \"offensiveness_score\"\n",
    "COMMENT_COLUMN = \"txt\"\n",
    "OFFENSIVE_LABEL = \"offensive\"\n",
    "NOT_OFFENSIVE_LABEL = \"not_offensive\"\n",
    "\n",
    "STOPWORDS_LANGUAGE = \"english\"\n",
    "MAX_DF = 0.75\n",
    "\n",
    "COUNT_VECTORIZER_PATH = \"models/count_vectorizer.pickle\"\n",
    "TF_IDF_VECTORIZER_PATH = \"models/tf_idf_vectorizer.pickle\"\n",
    "\n",
    "COUNT_SVM_MODEL_PATH = \"models/count_svm_model.pickle\"\n",
    "TF_IDF_SVM_MODEL_PATH = \"models/tf_idf_svm_model.pickle\"\n",
    "COUNT_NB_MODEL_PATH = \"models/count_nb_model.pickle\"\n",
    "TF_IDF_NB_MODEL_PATH = \"models/tf_idf_nb_model.pickle\"\n",
    "\n",
    "COUNT_SVM_TITLE = \"COUNT - SVM\"\n",
    "TF_IDF_SVM_TITLE = \"TF IDF - SVM\"\n",
    "COUNT_NB_TITLE = \"COUNT - NB\"\n",
    "TF_IDF_NB_TITLE = \"TF IDF - NB\"\n",
    "\n",
    "COUNT_SVM_STATS_PATH = \"stats/count_svm_stats.png\"\n",
    "TF_IDF_SVM_STATS_PATH = \"stats/tf_idf_svm_stats.png\"\n",
    "COUNT_NB_STATS_PATH = \"stats/count_nb_stats.png\"\n",
    "TF_IDF_NB_STATS_PATH = \"stats/tf_idf_nb_stats.png\"\n",
    "\n",
    "\n",
    "FIGURE_DPI = 240\n",
    "\n",
    "SEED = 1928"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(DATASET_PATH)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drops unused columns\n",
    "dataset.drop(UNUSED_COLUMNS, axis=\"columns\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drops deleted comments\n",
    "dataset[COMMENT_COLUMN].replace(\"[deleted]\", np.nan, inplace=True)\n",
    "dataset.dropna(subset=[COMMENT_COLUMN], inplace=True)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "middle = np.quantile(dataset[SCORE_COLUMN], 0.5)\n",
    "print(\"middle:\", middle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(dataset[SCORE_COLUMN], bins=\"auto\")\n",
    "plt.axvline(middle, color=\"k\")\n",
    "_ = plt.title(\"Offensiveness Score Distribution\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = dataset[COMMENT_COLUMN]\n",
    "y = dataset[SCORE_COLUMN].map(lambda s: OFFENSIVE_LABEL if s > 0 else NOT_OFFENSIVE_LABEL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer = CountVectorizer(stop_words=STOPWORDS_LANGUAGE, max_df=MAX_DF)\n",
    "count_vectorizer.fit(dataset[COMMENT_COLUMN])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_vectorizer = TfidfVectorizer(stop_words=STOPWORDS_LANGUAGE, max_df=MAX_DF)\n",
    "tf_idf_vectorizer.fit(dataset[COMMENT_COLUMN])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, train_size=0.8, random_state=SEED)\n",
    "count_x_train = count_vectorizer.transform(x_train)\n",
    "count_x_test = count_vectorizer.transform(x_test)\n",
    "tf_idf_x_train = tf_idf_vectorizer.transform(x_train)\n",
    "tf_idf_x_test = tf_idf_vectorizer.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_svm_classifier = SVC(probability=True)\n",
    "count_svm_classifier.fit(count_x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_svm_classifier = SVC(probability=True)\n",
    "tf_idf_svm_classifier.fit(tf_idf_x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_nb_classifier = MultinomialNB()\n",
    "count_nb_classifier.fit(count_x_train.toarray(), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_nb_classifier = GaussianNB()\n",
    "tf_idf_nb_classifier.fit(tf_idf_x_train.toarray(), y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_report_and_confusion(classifier, x_test, y_test):\n",
    "    classes = classifier.classes_\n",
    "    y_pred = classifier.predict(x_test)\n",
    "    report = pd.DataFrame(classification_report(y_test, y_pred, output_dict=True)).transpose()\n",
    "    confusion = pd.DataFrame(confusion_matrix(y_test, y_pred))\n",
    "    confusion.set_axis(classes, axis=\"rows\", inplace=True)\n",
    "    confusion.set_axis(classes, axis=\"columns\", inplace=True)\n",
    "    return [report, confusion]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_report_and_confusion(report, confusion, title, fig_path):\n",
    "    fig, main_axis = plt.subplots(1, 1)\n",
    "    main_axis.axis(\"tight\")\n",
    "    main_axis.axis(\"off\")\n",
    "    [report_axis, confusion_axis] = fig.subplots(2, 1)\n",
    "    report_axis.axis(\"tight\")\n",
    "    report_axis.axis(\"off\")\n",
    "    pdplt.table(report_axis, report, loc=\"center\")\n",
    "    report_axis.set_title(title)\n",
    "    confusion_axis.axis(\"tight\")\n",
    "    confusion_axis.axis(\"off\")\n",
    "    pdplt.table(confusion_axis, confusion, loc=\"center\")\n",
    "    confusion_axis.set_title(\"Matriz de Confus√£o\")\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(fig_path, bbox_inches=\"tight\", dpi=FIGURE_DPI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_stats(classifier, x_test, y_test, title, fig_path):\n",
    "    [report, confusion] = generate_report_and_confusion(classifier, x_test, y_test)\n",
    "    plot_report_and_confusion(report, confusion, title, fig_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_stats(count_svm_classifier, count_x_test, y_test, COUNT_SVM_TITLE, COUNT_SVM_STATS_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_stats(tf_idf_svm_classifier, tf_idf_x_test, y_test, TF_IDF_SVM_TITLE, TF_IDF_SVM_STATS_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_stats(count_nb_classifier, count_x_test, y_test, COUNT_NB_TITLE, COUNT_NB_STATS_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_stats(tf_idf_nb_classifier, tf_idf_x_test.toarray(), y_test, TF_IDF_NB_TITLE, TF_IDF_NB_STATS_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saves model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pickle_to_file(object, path):\n",
    "    with open(path, \"wb\") as file:\n",
    "        pk.dump(object, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_to_file(count_vectorizer, COUNT_VECTORIZER_PATH)\n",
    "pickle_to_file(tf_idf_vectorizer, TF_IDF_VECTORIZER_PATH)\n",
    "\n",
    "pickle_to_file(count_svm_classifier, COUNT_SVM_MODEL_PATH)\n",
    "pickle_to_file(tf_idf_svm_classifier, TF_IDF_SVM_MODEL_PATH)\n",
    "pickle_to_file(count_nb_classifier, COUNT_NB_MODEL_PATH)\n",
    "pickle_to_file(tf_idf_nb_classifier, TF_IDF_NB_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comment = \"\"\n",
    "vectorized = tf_idf_vectorizer.transform([comment])\n",
    "prediction = tf_idf_svm_classifier.predict(vectorized)\n",
    "print(f\"offensiveness: {prediction[0]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "eb527631bb171dc6780ad93b516f58282b63f6e85a0ece7e5e91665eeb4222d6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
